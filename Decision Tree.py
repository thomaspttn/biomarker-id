# -*- coding: utf-8 -*-
"""Bioinformatics Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bmFoikf-GIq7JGQZRdhSqwoXnPkZMSsn
"""

# Author: McKenzie Hawkins, mjh244
# Performs classification using a decision tree

# Imports
import matplotlib.pyplot as plt
import csv
from sklearn import tree
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score


# Lists to hold data
data = []
features = []
labels = []

# Reads the features and labels from the brca-normalized file
with open('brca-normalized.csv','r') as file: 
  for line in csv.reader(file):
    if (line[0] != ""):
      data.append(line) 
      features.append(line[1:25])
      labels.append(line[25])

# Prints out features and labels for verification
print("Features")
print(features)
print()
print("Labels")
print(labels)
print()

# Converts elements in labels and features lists to float
for i in range(len(labels)):
  labels[i] = float(labels[i])
for i in range(len(features)):
  for j in range(len(features[i])):
    features[i][j] = float(features[i][j])

################################################################################
# Decision Tree
################################################################################

# Splits data into 80% training and 20% testing
features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2, random_state=3)

# Creates the decision tree
classifierTree = tree.DecisionTreeClassifier(random_state=3)

# Fits the tree to the data
classifierTree = classifierTree.fit(features_train, labels_train)

# Makes the predictions
labels_predictions = classifierTree.predict(features_test)

# Prints the accuracy of the predictions
print("Accuracy score of decision tree")
print(accuracy_score(labels_test, labels_predictions))

# Plots the decision tree image
#plt.figure(figsize=(125,120))
#tree.plot_tree(classifierTree)

################################################################################
# SVM
################################################################################
from sklearn import svm

# Splits data into 80% training and 20% testing
features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2, random_state=3)

# Creates the SVM model
classifierSVM = svm.SVC(kernel = 'linear', random_state=3)

# Fits the tree to the data
classifierSVM = classifierSVM.fit(features_train, labels_train)

# Makes the predictions
labels_predictions = classifierSVM.predict(features_test)

# Prints the accuracy of the predictions
print("Accuracy score of SVM")
print(accuracy_score(labels_test, labels_predictions))

################################################################################
# Stochastic Gradient Descent
################################################################################
from sklearn.linear_model import SGDClassifier

# Splits data into 80% training and 20% testing
features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2)

# Creates the SVM model
classifierSGD = SGDClassifier()

# Fits the tree to the data
classifierSGD = classifierSGD.fit(features_train, labels_train)

# Makes the predictions
labels_predictions = classifierSGD.predict(features_test)

# Prints the accuracy of the predictions
print("Accuracy score of SGD")
print(accuracy_score(labels_test, labels_predictions))

################################################################################
# Gaussian Naive Bayes
################################################################################
from sklearn.naive_bayes import GaussianNB

# Splits data into 80% training and 20% testing
features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2)

# Creates the SVM model
classifierNB = GaussianNB()

# Fits the tree to the data
classifierNB = classifierNB.fit(features_train, labels_train)

# Makes the predictions
labels_predictions = classifierNB.predict(features_test)

# Prints the accuracy of the predictions
print("Accuracy score of Gaussian NB")
print(accuracy_score(labels_test, labels_predictions))

################################################################################
# Complement Naive Bayes
################################################################################
from sklearn.naive_bayes import ComplementNB

# Splits data into 80% training and 20% testing
features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2)

# Creates the SVM model
classifierNB = ComplementNB()

# Fits the tree to the data
classifierNB = classifierNB.fit(features_train, labels_train)

# Makes the predictions
labels_predictions = classifierNB.predict(features_test)

# Prints the accuracy of the predictions
print("Accuracy score of Complementary NB")
print(accuracy_score(labels_test, labels_predictions))

################################################################################
# Categorical Naive Bayes
################################################################################
from sklearn.naive_bayes import CategoricalNB

# Splits data into 80% training and 20% testing
features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2)

# Creates the SVM model
classifierNB = CategoricalNB()

# Fits the tree to the data
classifierNB = classifierNB.fit(features_train, labels_train)

# Makes the predictions
labels_predictions = classifierNB.predict(features_test)

# Prints the accuracy of the predictions
print("Accuracy score of Categorical NB")
print(accuracy_score(labels_test, labels_predictions))

################################################################################
# Logistic Regression
################################################################################
from sklearn.linear_model import LogisticRegression

# Splits data into 80% training and 20% testing
features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2)

# Creates the SVM model
classifierLR = LogisticRegression()

# Fits the tree to the data
classifierLR = classifierLR.fit(features_train, labels_train)

# Makes the predictions
labels_predictions = classifierLR.predict(features_test)

# Prints the accuracy of the predictions
print("Accuracy score of LR")
print(accuracy_score(labels_test, labels_predictions))

################################################################################
# K Nearest Neighbours
################################################################################
from sklearn.neighbors import KNeighborsClassifier

# Splits data into 80% training and 20% testing
features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2)

# Creates the SVM model
classifierKNN = KNeighborsClassifier()

# Fits the tree to the data
classifierKNN = classifierKNN.fit(features_train, labels_train)

# Makes the predictions
labels_predictions = classifierKNN.predict(features_test)

# Prints the accuracy of the predictions
print("Accuracy score of KNN")
print(accuracy_score(labels_test, labels_predictions))

